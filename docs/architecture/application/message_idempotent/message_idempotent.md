# Message Idempotent(消息幂等)

## 什么是消息幂等

当出现消费者对某条消息重复消费的情况时，重复消费的结果与消费一次的结果是相同的，并且多次消费并未对业务系统产生任何负面影响，那么这个消费者的处理过程就是幂等的。

例如，在支付场景下，消费者消费一笔扣款消息，对账户进行扣款操作，扣款金额为100元。但是由于网络或其他系统问题，上层支付引擎重复投递扣款消息。消费者重复消费了该扣款消息，但最终的业务结果是只扣款一次，扣费100元，且用户的扣款记录中对应的订单只有一条扣款流水，不会多次扣除。这说明整个消费过程实现了消费幂等。

----

## 产生幂等问题的场景

**发送端消息重复投递**

- 由于网络抖动等原因发送失败进行重试操作时，生产者意识到消息发送失败并发起重试时，消费者后续有可能收到两条重复的消息
- 生产者异步发送时，Producer Client配置了重试
- 持久化消息定时任务没有乐观锁更新中间态机制，导致记录被重复捞取，重复投递

**Broker端消息重复投递**

- 消息队列内部机制，会尽最大努力投递；为了保证消息至少被消费一次，消息队列在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且Message ID也相同的消息
- 消费者端自动提交offset，但是由于各种异常原因提交失败（例如逻辑与拉取同步，逻辑异常没有提交offset；异步提交offset，但是在提交线程执行工作前宕机等）；导致消费者端恢复时，获取的仍是之前的offset，导致消息重复消费

----

## 解决方案

以中间件生成的全局唯一`MessageId`和业务幂等Key搭配，共同完成消息幂等处理。首先，MessageId作为全局唯一的标识，表示一条消息的唯一性；但是，由于生产者方的不可控因素(作为中间件和消费者，我们是无法控制生产者什么时候产生消息、什么时候会重复推送消息)，那就会导致同样内容的Message有不同的MessageId。

而消费者首先可以根据MessageId进行第一层过滤: 即MesageId如果已存在则不再处理；否则进入到基于`业务幂等KEY`的幂等处理逻辑。

### MessageId生成方案

- RocketMQ默认消息体携带MessageId，Consumer转换`MessageExt`对象后，可以直接获取，进行后续业务逻辑
- Kafka配置自定义序列化器，在Producer生成的消息体中添加MessageId
- 封装工具包，在抽象类中定义MessageId，在通用的消息发送组件中生成

### 业务幂等KEY生成方案

- 上下游约定报文数据结构，以某一字段作为业务幂等KEY
- 消息生产者需要保证该字段的值，在所属平台是唯一的

### 利用Redis进行幂等判断

基于Redis的`SETNXPX`指令，完成原子化加锁并设置过期时间


优势在于Redis的性能足以支撑绝大多数场景；缺点明显，如果只依赖Redis进行处理，在无法保证Redis高可用的情况下，会有失效的情况
- 例如：缓存服务不可用、缓存主从同步延迟、集群节点下线等

所以该方案作为第一道拦截，即使通过，还需要后续处理流程

### 基于数据库唯一索引

创建一张`message_request`表，以`业务幂等KEY`作为唯一索引

涉及幂等的字段值同时落表，如果触发幂等异常，需要检查两条消息的幂等字段的值是否一致；如果一致，进行幂等处理（触发后续流程或不处理）；否则，需要将错误原因记录数据表，并推送告警供上下游排查

**为什么要落幂等字段值？**

幂等：`f(f(x)) = f(x)`；即两个相同的请求，处理结果也要相同。所谓的相同，就是幂等字段要一致，才可以认定是相同的请求，否则除首条消息外的请求，都应该记为非法消息。

### 业务层面去重处理

业务表设置合理的唯一索引：对于消息生产者来说，消费者无法100%相信其对业务幂等KEY全局唯一的承诺。生产者很有可能对同样的一条消息的幂等KEY设置不同的值

针对这样的情况，消费者需要根据业务场景，在业务流程中采用合理的防重措施

- 以账户流水为例：`同一订单号、同一交易流水号、同一账户、同一交易方向只允许有一条记录`。这样，即使是重复的交易，仍然可以被拦截，避免资金的损失

同理，上述方案仍可以采用`Redis为主 + 数据库辅助`的手段实现，以提升系统性能

> **关于是否应该使用BloomFilter的思考**
>
> BloomFilter布隆过滤器的特性确实适合这种防重的场景，不在的`BitMap`的数据一定是不存在的，可以直接通过幂等校验(无论是消息MessageId幂等处理，还是业务幂等KEY处理)；存在`BitMap`的数据可能是误伤，需要进行幂等性校验的逻辑。
>
> 幂等性校验的成本可能不高，但是BloomFilter的一个问题就是在数据移除的时候很复杂，这会导致用误伤率换取空间的布隆过滤器在这一场景不太适用。
>
> 同时，消息类或者接口类的数据都具有一定的时效性，一般来说超过7天甚至几小时的重复投递都不存在。如果旧数据一直维护在`BitMap`中，这是不合理的。

**参考**

> 为Kafka的每条消息加上MessageID: https://www.jianshu.com/p/0d287d5c3bbc
